{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# train = pd.read_csv(r'C:/Users/DC/OneDrive - 계명대학교/DC/2024/2024_날씨빅콘/데셋/train_fi.csv')\n",
    "test = pd.read_csv(r'C:/Users/DC/OneDrive - 계명대학교/DC/2024/2024_날씨빅콘/데셋/test_fi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7593181 entries, 0 to 7593180\n",
      "Data columns (total 93 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   격자넘버           int64  \n",
      " 1   시간             int64  \n",
      " 2   지점번호           int64  \n",
      " 3   기온             float64\n",
      " 4   상대습도           float64\n",
      " 5   풍속             float64\n",
      " 6   강수량            float64\n",
      " 7   체감온도           float64\n",
      " 8   요일             int64  \n",
      " 9   주중주말           int64  \n",
      " 10  전력기상지수         float64\n",
      " 11  계절             object \n",
      " 12  년              int64  \n",
      " 13  월              int64  \n",
      " 14  일              int64  \n",
      " 15  기온_mean_num    float64\n",
      " 16  기온_std_num     float64\n",
      " 17  기온_skew_num    float64\n",
      " 18  상대습도_mean_num  float64\n",
      " 19  상대습도_std_num   float64\n",
      " 20  상대습도_skew_num  float64\n",
      " 21  풍속_mean_num    float64\n",
      " 22  풍속_std_num     float64\n",
      " 23  풍속_skew_num    float64\n",
      " 24  강수량_mean_num   float64\n",
      " 25  강수량_std_num    float64\n",
      " 26  강수량_skew_num   float64\n",
      " 27  체감온도_mean_num  float64\n",
      " 28  체감온도_std_num   float64\n",
      " 29  체감온도_skew_num  float64\n",
      " 30  기온_mean_bn     float64\n",
      " 31  기온_std_bn      float64\n",
      " 32  기온_skew_bn     float64\n",
      " 33  상대습도_mean_bn   float64\n",
      " 34  상대습도_std_bn    float64\n",
      " 35  상대습도_skew_bn   float64\n",
      " 36  풍속_mean_bn     float64\n",
      " 37  풍속_std_bn      float64\n",
      " 38  풍속_skew_bn     float64\n",
      " 39  강수량_mean_bn    float64\n",
      " 40  강수량_std_bn     float64\n",
      " 41  강수량_skew_bn    float64\n",
      " 42  체감온도_mean_bn   float64\n",
      " 43  체감온도_std_bn    float64\n",
      " 44  체감온도_skew_bn   float64\n",
      " 45  기온_mean_ms     float64\n",
      " 46  기온_std_ms      float64\n",
      " 47  기온_skew_ms     float64\n",
      " 48  상대습도_mean_ms   float64\n",
      " 49  상대습도_std_ms    float64\n",
      " 50  상대습도_skew_ms   float64\n",
      " 51  풍속_mean_ms     float64\n",
      " 52  풍속_std_ms      float64\n",
      " 53  풍속_skew_ms     float64\n",
      " 54  강수량_mean_ms    float64\n",
      " 55  강수량_std_ms     float64\n",
      " 56  강수량_skew_ms    float64\n",
      " 57  체감온도_mean_ms   float64\n",
      " 58  체감온도_std_ms    float64\n",
      " 59  체감온도_skew_ms   float64\n",
      " 60  기온_mean_tm     float64\n",
      " 61  기온_std_tm      float64\n",
      " 62  기온_skew_tm     float64\n",
      " 63  상대습도_mean_tm   float64\n",
      " 64  상대습도_std_tm    float64\n",
      " 65  상대습도_skew_tm   float64\n",
      " 66  풍속_mean_tm     float64\n",
      " 67  풍속_std_tm      float64\n",
      " 68  풍속_skew_tm     float64\n",
      " 69  강수량_mean_tm    float64\n",
      " 70  강수량_std_tm     float64\n",
      " 71  강수량_skew_tm    float64\n",
      " 72  체감온도_mean_tm   float64\n",
      " 73  체감온도_std_tm    float64\n",
      " 74  체감온도_skew_tm   float64\n",
      " 75  기온_mean_we     float64\n",
      " 76  기온_std_we      float64\n",
      " 77  기온_skew_we     float64\n",
      " 78  상대습도_mean_we   float64\n",
      " 79  상대습도_std_we    float64\n",
      " 80  상대습도_skew_we   float64\n",
      " 81  풍속_mean_we     float64\n",
      " 82  풍속_std_we      float64\n",
      " 83  풍속_skew_we     float64\n",
      " 84  강수량_mean_we    float64\n",
      " 85  강수량_std_we     float64\n",
      " 86  강수량_skew_we    float64\n",
      " 87  체감온도_mean_we   float64\n",
      " 88  체감온도_std_we    float64\n",
      " 89  체감온도_skew_we   float64\n",
      " 90  체감온도_평균기온_차이   float64\n",
      " 91  CDH            float64\n",
      " 92  HDH            float64\n",
      "dtypes: float64(84), int64(8), object(1)\n",
      "memory usage: 5.3+ GB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object 타입의 열: Index(['계절'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "object_columns = train.select_dtypes(include=['object']).columns\n",
    "print(\"Object 타입의 열:\", object_columns)\n",
    "train = pd.get_dummies(train, columns=object_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boolean 값을 정수형으로 변환\n",
    "train = train.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2838143 entries, 0 to 2838142\n",
      "Data columns (total 92 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   격자넘버           int64  \n",
      " 1   시간             int64  \n",
      " 2   지점번호           int64  \n",
      " 3   기온             float64\n",
      " 4   상대습도           float64\n",
      " 5   풍속             float64\n",
      " 6   강수량            float64\n",
      " 7   체감온도           float64\n",
      " 8   요일             int64  \n",
      " 9   주중주말           int64  \n",
      " 10  계절             object \n",
      " 11  년              int64  \n",
      " 12  월              int64  \n",
      " 13  일              int64  \n",
      " 14  기온_mean_num    float64\n",
      " 15  기온_std_num     float64\n",
      " 16  기온_skew_num    float64\n",
      " 17  상대습도_mean_num  float64\n",
      " 18  상대습도_std_num   float64\n",
      " 19  상대습도_skew_num  float64\n",
      " 20  풍속_mean_num    float64\n",
      " 21  풍속_std_num     float64\n",
      " 22  풍속_skew_num    float64\n",
      " 23  강수량_mean_num   float64\n",
      " 24  강수량_std_num    float64\n",
      " 25  강수량_skew_num   float64\n",
      " 26  체감온도_mean_num  float64\n",
      " 27  체감온도_std_num   float64\n",
      " 28  체감온도_skew_num  float64\n",
      " 29  기온_mean_bn     float64\n",
      " 30  기온_std_bn      float64\n",
      " 31  기온_skew_bn     float64\n",
      " 32  상대습도_mean_bn   float64\n",
      " 33  상대습도_std_bn    float64\n",
      " 34  상대습도_skew_bn   float64\n",
      " 35  풍속_mean_bn     float64\n",
      " 36  풍속_std_bn      float64\n",
      " 37  풍속_skew_bn     float64\n",
      " 38  강수량_mean_bn    float64\n",
      " 39  강수량_std_bn     float64\n",
      " 40  강수량_skew_bn    float64\n",
      " 41  체감온도_mean_bn   float64\n",
      " 42  체감온도_std_bn    float64\n",
      " 43  체감온도_skew_bn   float64\n",
      " 44  기온_mean_ms     float64\n",
      " 45  기온_std_ms      float64\n",
      " 46  기온_skew_ms     float64\n",
      " 47  상대습도_mean_ms   float64\n",
      " 48  상대습도_std_ms    float64\n",
      " 49  상대습도_skew_ms   float64\n",
      " 50  풍속_mean_ms     float64\n",
      " 51  풍속_std_ms      float64\n",
      " 52  풍속_skew_ms     float64\n",
      " 53  강수량_mean_ms    float64\n",
      " 54  강수량_std_ms     float64\n",
      " 55  강수량_skew_ms    float64\n",
      " 56  체감온도_mean_ms   float64\n",
      " 57  체감온도_std_ms    float64\n",
      " 58  체감온도_skew_ms   float64\n",
      " 59  기온_mean_tm     float64\n",
      " 60  기온_std_tm      float64\n",
      " 61  기온_skew_tm     float64\n",
      " 62  상대습도_mean_tm   float64\n",
      " 63  상대습도_std_tm    float64\n",
      " 64  상대습도_skew_tm   float64\n",
      " 65  풍속_mean_tm     float64\n",
      " 66  풍속_std_tm      float64\n",
      " 67  풍속_skew_tm     float64\n",
      " 68  강수량_mean_tm    float64\n",
      " 69  강수량_std_tm     float64\n",
      " 70  강수량_skew_tm    float64\n",
      " 71  체감온도_mean_tm   float64\n",
      " 72  체감온도_std_tm    float64\n",
      " 73  체감온도_skew_tm   float64\n",
      " 74  기온_mean_we     float64\n",
      " 75  기온_std_we      float64\n",
      " 76  기온_skew_we     float64\n",
      " 77  상대습도_mean_we   float64\n",
      " 78  상대습도_std_we    float64\n",
      " 79  상대습도_skew_we   float64\n",
      " 80  풍속_mean_we     float64\n",
      " 81  풍속_std_we      float64\n",
      " 82  풍속_skew_we     float64\n",
      " 83  강수량_mean_we    float64\n",
      " 84  강수량_std_we     float64\n",
      " 85  강수량_skew_we    float64\n",
      " 86  체감온도_mean_we   float64\n",
      " 87  체감온도_std_we    float64\n",
      " 88  체감온도_skew_we   float64\n",
      " 89  체감온도_평균기온_차이   float64\n",
      " 90  CDH            float64\n",
      " 91  HDH            float64\n",
      "dtypes: float64(83), int64(8), object(1)\n",
      "memory usage: 1.9+ GB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "epoch 0  | loss: 157.81074| val_0_rmse: 5.54347 |  0:04:56s\n",
      "epoch 1  | loss: 32.94807| val_0_rmse: 5.36229 |  0:09:22s\n",
      "epoch 2  | loss: 30.46575| val_0_rmse: 5.04574 |  0:13:49s\n",
      "epoch 3  | loss: 28.62292| val_0_rmse: 5.00003 |  0:18:14s\n",
      "epoch 4  | loss: 27.6523 | val_0_rmse: 5.18906 |  0:22:42s\n",
      "epoch 5  | loss: 27.44149| val_0_rmse: 5.08769 |  0:27:08s\n",
      "epoch 6  | loss: 27.35669| val_0_rmse: 4.93839 |  0:31:33s\n",
      "epoch 7  | loss: 27.0736 | val_0_rmse: 4.85395 |  0:35:56s\n",
      "epoch 8  | loss: 26.80343| val_0_rmse: 4.97945 |  0:40:19s\n",
      "epoch 9  | loss: 26.50044| val_0_rmse: 4.92178 |  0:44:41s\n",
      "epoch 10 | loss: 26.8736 | val_0_rmse: 4.85291 |  0:49:04s\n",
      "epoch 11 | loss: 26.37037| val_0_rmse: 4.75167 |  0:53:26s\n",
      "epoch 12 | loss: 26.21083| val_0_rmse: 4.88002 |  0:57:49s\n",
      "epoch 13 | loss: 25.52691| val_0_rmse: 4.87282 |  1:02:11s\n",
      "epoch 14 | loss: 25.19919| val_0_rmse: 4.94088 |  1:06:33s\n",
      "epoch 15 | loss: 25.16069| val_0_rmse: 4.66147 |  1:10:56s\n",
      "epoch 16 | loss: 24.98192| val_0_rmse: 4.64539 |  1:15:19s\n",
      "epoch 17 | loss: 25.51161| val_0_rmse: 4.93582 |  1:19:42s\n",
      "epoch 18 | loss: 25.42633| val_0_rmse: 5.59305 |  1:24:04s\n",
      "epoch 19 | loss: 25.303  | val_0_rmse: 4.789   |  1:28:26s\n",
      "epoch 20 | loss: 25.03409| val_0_rmse: 4.77766 |  1:32:47s\n",
      "epoch 21 | loss: 24.94993| val_0_rmse: 4.69614 |  1:37:09s\n",
      "epoch 22 | loss: 24.73733| val_0_rmse: 4.66616 |  1:41:31s\n",
      "epoch 23 | loss: 24.6907 | val_0_rmse: 4.72599 |  1:45:52s\n",
      "epoch 24 | loss: 24.4898 | val_0_rmse: 4.87152 |  1:50:14s\n",
      "epoch 25 | loss: 24.19751| val_0_rmse: 4.93266 |  1:54:36s\n",
      "epoch 26 | loss: 24.2297 | val_0_rmse: 4.652   |  1:58:58s\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_rmse = 4.64539\n",
      "[CV] END gamma=2.0, lambda_sparse=0.0001, n_a=8, n_d=8, n_steps=5; total time=119.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 210.43493| val_0_rmse: 6.98475 |  0:04:22s\n",
      "epoch 1  | loss: 44.268  | val_0_rmse: 6.09675 |  0:08:45s\n",
      "epoch 2  | loss: 35.42844| val_0_rmse: 5.75779 |  0:13:06s\n",
      "epoch 3  | loss: 31.56798| val_0_rmse: 5.82487 |  0:17:28s\n",
      "epoch 4  | loss: 29.9428 | val_0_rmse: 5.35753 |  0:21:50s\n",
      "epoch 5  | loss: 29.79002| val_0_rmse: 5.19861 |  0:26:12s\n",
      "epoch 6  | loss: 27.81145| val_0_rmse: 5.86507 |  0:30:34s\n",
      "epoch 7  | loss: 28.08415| val_0_rmse: 4.86104 |  0:34:56s\n",
      "epoch 8  | loss: 27.60313| val_0_rmse: 5.45555 |  0:39:18s\n",
      "epoch 9  | loss: 26.96721| val_0_rmse: 5.11567 |  0:43:40s\n",
      "epoch 10 | loss: 27.24981| val_0_rmse: 4.93857 |  0:48:01s\n",
      "epoch 11 | loss: 26.73582| val_0_rmse: 12.53103|  0:52:24s\n",
      "epoch 12 | loss: 26.49151| val_0_rmse: 5.77916 |  0:56:46s\n",
      "epoch 13 | loss: 26.53871| val_0_rmse: 6.35827 |  1:01:08s\n",
      "epoch 14 | loss: 26.26198| val_0_rmse: 7.52699 |  1:05:31s\n",
      "epoch 15 | loss: 25.69684| val_0_rmse: 4.67852 |  1:09:55s\n",
      "epoch 16 | loss: 27.29192| val_0_rmse: 6.61807 |  1:14:17s\n",
      "epoch 17 | loss: 26.23863| val_0_rmse: 6.70938 |  1:18:41s\n",
      "epoch 18 | loss: 25.92624| val_0_rmse: 5.25551 |  1:23:11s\n",
      "epoch 19 | loss: 25.62551| val_0_rmse: 6.31289 |  1:27:42s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 49\u001b[0m\n\u001b[0;32m     37\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m     38\u001b[0m     tabnet, \n\u001b[0;32m     39\u001b[0m     param_dist, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     46\u001b[0m )\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# 조기 중지 설정을 포함하여 모델 학습\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m                  \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrmse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                  \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_np\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters found by Random Search:\u001b[39m\u001b[38;5;124m\"\u001b[39m, random_search\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest cross-validation MSE by Random Search:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m-\u001b[39mrandom_search\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1914\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1914\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1916\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1918\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 895\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:258\u001b[0m, in \u001b[0;36mTabModel.fit\u001b[1;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations, compute_importance)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_epochs):\n\u001b[0;32m    254\u001b[0m \n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# Call method on_epoch_begin for all callbacks\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_container\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch_idx)\n\u001b[1;32m--> 258\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Apply predict epoch to all eval sets\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m eval_name, valid_dataloader \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(eval_names, valid_dataloaders):\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:486\u001b[0m, in \u001b[0;36mTabModel._train_epoch\u001b[1;34m(self, train_loader)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;124;03mTrains one epoch of the network in self.network\u001b[39;00m\n\u001b[0;32m    478\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;124;03m    DataLoader with train set\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m--> 486\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callback_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_batch_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_logs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransposed\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:183\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m collate(\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:183\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m collate([\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# train 데이터프레임이 이미 정의되어 있어야 합니다.\n",
    "# 예시: train = pd.read_csv('train.csv')\n",
    "\n",
    "X = train.drop('전력기상지수', axis=1)\n",
    "y = train['전력기상지수']\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 목표 변수 numpy array로 변환 후 reshape\n",
    "y_train_np = y_train.values.reshape(-1, 1)\n",
    "y_val_np = y_val.values.reshape(-1, 1)\n",
    "\n",
    "# TabNet 모델 생성\n",
    "tabnet = TabNetRegressor()\n",
    "\n",
    "# 랜덤 서치 파라미터 설정\n",
    "param_dist = {\n",
    "    'n_d': [8, 16, 24, 32, 64],\n",
    "    'n_a': [8, 16, 24, 32, 64],\n",
    "    'n_steps': [3, 5, 7, 9, 11],\n",
    "    'gamma': [1.0, 1.5, 2.0, 2.5],\n",
    "    'lambda_sparse': [0, 1e-4, 1e-3, 1e-2]\n",
    "}\n",
    "\n",
    "# 데이터 numpy array로 변환\n",
    "X_train_np = X_train.values\n",
    "X_val_np = X_val.values\n",
    "\n",
    "# 랜덤 서치\n",
    "random_search = RandomizedSearchCV(\n",
    "    tabnet, \n",
    "    param_dist, \n",
    "    n_iter=20, \n",
    "    cv=5, \n",
    "    scoring='neg_mean_squared_error', \n",
    "    n_jobs=1, \n",
    "    verbose=2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 조기 중지 설정을 포함하여 모델 학습\n",
    "random_search.fit(X_train_np, y_train_np, \n",
    "                  max_epochs=200, \n",
    "                  patience=10, \n",
    "                  eval_metric=['rmse'], \n",
    "                  eval_set=[(X_val_np, y_val_np)])\n",
    "\n",
    "print(\"Best parameters found by Random Search:\", random_search.best_params_)\n",
    "print(\"Best cross-validation MSE by Random Search:\", -random_search.best_score_)\n",
    "\n",
    "# 검증 데이터에 대한 예측\n",
    "y_pred_random = random_search.predict(X_val_np)\n",
    "\n",
    "# 평가 지표 계산\n",
    "mae = mean_absolute_error(y_val_np, y_pred_random)\n",
    "mse = mean_squared_error(y_val_np, y_pred_random)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val_np, y_pred_random)\n",
    "\n",
    "print(\"Validation MAE by Random Search:\", mae)\n",
    "print(\"Validation MSE by Random Search:\", mse)\n",
    "print(\"Validation RMSE by Random Search:\", rmse)\n",
    "print(\"Validation R² by Random Search:\", r2)\n",
    "\n",
    "# 랜덤 서치에서 최적의 파라미터 추출\n",
    "best_params = random_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 178.59372| val_0_rmse: 7.00075 |  0:03:22s\n",
      "epoch 1  | loss: 43.05306| val_0_rmse: 6.5761  |  0:06:40s\n",
      "epoch 2  | loss: 36.88758| val_0_rmse: 6.31536 |  0:09:53s\n",
      "epoch 3  | loss: 34.54943| val_0_rmse: 5.70431 |  0:13:05s\n",
      "epoch 4  | loss: 35.51806| val_0_rmse: 5.75979 |  0:16:16s\n",
      "epoch 5  | loss: 33.83595| val_0_rmse: 5.56334 |  0:19:27s\n",
      "epoch 6  | loss: 32.72221| val_0_rmse: 5.6095  |  0:22:39s\n",
      "epoch 7  | loss: 32.39753| val_0_rmse: 5.41635 |  0:25:52s\n",
      "epoch 8  | loss: 32.08882| val_0_rmse: 5.16174 |  0:29:03s\n",
      "epoch 9  | loss: 30.54395| val_0_rmse: 5.23892 |  0:32:15s\n",
      "epoch 10 | loss: 29.56623| val_0_rmse: 5.28964 |  0:35:26s\n",
      "epoch 11 | loss: 29.59462| val_0_rmse: 5.91515 |  0:38:37s\n",
      "epoch 12 | loss: 29.66732| val_0_rmse: 5.57093 |  0:41:49s\n",
      "epoch 13 | loss: 29.10019| val_0_rmse: 5.35448 |  0:45:01s\n",
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 8 and best_val_0_rmse = 5.16174\n",
      "[CV] END gamma=1.8, lambda_sparse=0.0001, n_a=8, n_d=8, n_steps=4; total time=45.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 169.73413| val_0_rmse: 5.72258 |  0:03:13s\n",
      "epoch 1  | loss: 36.08628| val_0_rmse: 5.8792  |  0:06:26s\n",
      "epoch 2  | loss: 32.11274| val_0_rmse: 5.20068 |  0:09:39s\n",
      "epoch 3  | loss: 30.37441| val_0_rmse: 5.04943 |  0:12:52s\n",
      "epoch 4  | loss: 29.26138| val_0_rmse: 4.98788 |  0:16:05s\n",
      "epoch 5  | loss: 28.71488| val_0_rmse: 4.97945 |  0:19:18s\n",
      "epoch 6  | loss: 27.96233| val_0_rmse: 5.10107 |  0:22:32s\n",
      "epoch 7  | loss: 27.4189 | val_0_rmse: 5.33059 |  0:25:46s\n",
      "epoch 8  | loss: 27.03511| val_0_rmse: 4.87643 |  0:29:02s\n",
      "epoch 9  | loss: 26.60256| val_0_rmse: 5.46678 |  0:32:18s\n",
      "epoch 10 | loss: 27.04553| val_0_rmse: 5.18455 |  0:35:33s\n",
      "epoch 11 | loss: 26.34109| val_0_rmse: 4.86041 |  0:38:47s\n",
      "epoch 12 | loss: 25.94653| val_0_rmse: 4.80381 |  0:42:01s\n",
      "epoch 13 | loss: 25.79829| val_0_rmse: 4.94285 |  0:45:15s\n",
      "epoch 14 | loss: 25.55814| val_0_rmse: 4.727   |  0:48:28s\n",
      "epoch 15 | loss: 25.39684| val_0_rmse: 4.86984 |  0:51:42s\n",
      "epoch 16 | loss: 25.39279| val_0_rmse: 8.40432 |  0:54:55s\n",
      "epoch 17 | loss: 25.31702| val_0_rmse: 5.4583  |  0:58:08s\n",
      "epoch 18 | loss: 25.16672| val_0_rmse: 4.85848 |  1:01:22s\n",
      "epoch 19 | loss: 25.07023| val_0_rmse: 4.719   |  1:04:35s\n",
      "epoch 20 | loss: 25.0807 | val_0_rmse: 4.7866  |  1:07:49s\n",
      "epoch 21 | loss: 24.91499| val_0_rmse: 4.86451 |  1:11:02s\n",
      "epoch 22 | loss: 24.79812| val_0_rmse: 5.35136 |  1:14:16s\n",
      "epoch 23 | loss: 24.79663| val_0_rmse: 5.0014  |  1:17:31s\n",
      "epoch 24 | loss: 24.7566 | val_0_rmse: 4.79129 |  1:20:45s\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 19 and best_val_0_rmse = 4.719\n",
      "[CV] END gamma=1.8, lambda_sparse=0.0001, n_a=8, n_d=8, n_steps=4; total time=81.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 172.41578| val_0_rmse: 5.85274 |  0:03:14s\n",
      "epoch 1  | loss: 40.54939| val_0_rmse: 5.7794  |  0:06:28s\n",
      "epoch 2  | loss: 35.68308| val_0_rmse: 5.39604 |  0:09:42s\n",
      "epoch 3  | loss: 33.05087| val_0_rmse: 5.22857 |  0:12:56s\n",
      "epoch 4  | loss: 31.84439| val_0_rmse: 5.32249 |  0:16:09s\n",
      "epoch 5  | loss: 30.99674| val_0_rmse: 5.1349  |  0:19:26s\n",
      "epoch 6  | loss: 29.93673| val_0_rmse: 5.19153 |  0:22:39s\n",
      "epoch 7  | loss: 29.41677| val_0_rmse: 5.08995 |  0:25:51s\n",
      "epoch 8  | loss: 28.89429| val_0_rmse: 4.94934 |  0:29:04s\n",
      "epoch 9  | loss: 28.5854 | val_0_rmse: 5.10586 |  0:32:18s\n",
      "epoch 10 | loss: 28.73862| val_0_rmse: 5.2538  |  0:35:30s\n",
      "epoch 11 | loss: 28.07037| val_0_rmse: 5.29502 |  0:38:43s\n",
      "epoch 12 | loss: 27.89264| val_0_rmse: 4.92431 |  0:41:57s\n",
      "epoch 13 | loss: 27.46484| val_0_rmse: 5.22949 |  0:45:10s\n",
      "epoch 14 | loss: 27.19005| val_0_rmse: 4.83775 |  0:48:25s\n",
      "epoch 15 | loss: 27.21597| val_0_rmse: 4.85994 |  0:51:42s\n",
      "epoch 16 | loss: 26.96217| val_0_rmse: 4.92107 |  0:55:04s\n",
      "epoch 17 | loss: 26.81523| val_0_rmse: 5.00145 |  0:58:20s\n",
      "epoch 18 | loss: 26.6903 | val_0_rmse: 5.2069  |  1:01:32s\n",
      "epoch 19 | loss: 26.61484| val_0_rmse: 4.86828 |  1:04:45s\n",
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 14 and best_val_0_rmse = 4.83775\n",
      "[CV] END gamma=1.8, lambda_sparse=0.0001, n_a=8, n_d=8, n_steps=4; total time=65.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 164.67378| val_0_rmse: 5.57471 |  0:03:12s\n",
      "epoch 1  | loss: 35.40491| val_0_rmse: 5.79712 |  0:06:25s\n",
      "epoch 2  | loss: 31.84667| val_0_rmse: 5.23469 |  0:09:38s\n",
      "epoch 3  | loss: 30.08286| val_0_rmse: 5.08061 |  0:12:51s\n",
      "epoch 4  | loss: 28.81296| val_0_rmse: 5.15911 |  0:16:04s\n",
      "epoch 5  | loss: 28.01098| val_0_rmse: 5.02216 |  0:19:18s\n",
      "epoch 6  | loss: 27.23171| val_0_rmse: 4.9914  |  0:22:31s\n",
      "epoch 7  | loss: 26.68517| val_0_rmse: 5.13837 |  0:25:44s\n",
      "epoch 8  | loss: 26.3741 | val_0_rmse: 4.85928 |  0:28:57s\n",
      "epoch 9  | loss: 26.00466| val_0_rmse: 5.05544 |  0:32:09s\n",
      "epoch 10 | loss: 26.04084| val_0_rmse: 4.9691  |  0:35:23s\n",
      "epoch 11 | loss: 25.61984| val_0_rmse: 5.48509 |  0:38:35s\n",
      "epoch 12 | loss: 25.42026| val_0_rmse: 5.80258 |  0:41:47s\n",
      "epoch 13 | loss: 25.26055| val_0_rmse: 4.94545 |  0:45:00s\n",
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 8 and best_val_0_rmse = 4.85928\n",
      "[CV] END gamma=1.8, lambda_sparse=0.001, n_a=8, n_d=8, n_steps=4; total time=45.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 165.51466| val_0_rmse: 5.41685 |  0:03:13s\n",
      "epoch 1  | loss: 32.96113| val_0_rmse: 5.44257 |  0:06:26s\n",
      "epoch 2  | loss: 30.26938| val_0_rmse: 5.33641 |  0:09:38s\n",
      "epoch 3  | loss: 28.8091 | val_0_rmse: 5.12041 |  0:12:52s\n",
      "epoch 4  | loss: 28.3546 | val_0_rmse: 5.03088 |  0:16:05s\n",
      "epoch 5  | loss: 27.47307| val_0_rmse: 4.97803 |  0:19:18s\n",
      "epoch 6  | loss: 27.0777 | val_0_rmse: 4.94156 |  0:22:31s\n",
      "epoch 7  | loss: 26.61705| val_0_rmse: 4.87773 |  0:25:46s\n",
      "epoch 8  | loss: 26.37084| val_0_rmse: 4.95152 |  0:28:59s\n",
      "epoch 9  | loss: 25.99396| val_0_rmse: 4.81634 |  0:32:13s\n",
      "epoch 10 | loss: 25.92387| val_0_rmse: 5.01851 |  0:35:26s\n",
      "epoch 11 | loss: 25.55316| val_0_rmse: 4.82515 |  0:38:40s\n",
      "epoch 12 | loss: 25.73013| val_0_rmse: 4.80854 |  0:41:53s\n",
      "epoch 13 | loss: 25.33456| val_0_rmse: 4.73716 |  0:45:06s\n",
      "epoch 14 | loss: 25.18675| val_0_rmse: 4.73699 |  0:48:20s\n",
      "epoch 15 | loss: 24.72661| val_0_rmse: 5.55204 |  0:51:33s\n",
      "epoch 16 | loss: 24.89383| val_0_rmse: 4.85442 |  0:54:47s\n",
      "epoch 17 | loss: 24.35641| val_0_rmse: 4.97619 |  0:58:00s\n",
      "epoch 18 | loss: 24.25442| val_0_rmse: 4.95529 |  1:01:13s\n",
      "epoch 19 | loss: 24.72807| val_0_rmse: 4.71377 |  1:04:27s\n",
      "epoch 20 | loss: 24.42858| val_0_rmse: 4.61763 |  1:07:41s\n",
      "epoch 21 | loss: 24.00792| val_0_rmse: 4.92146 |  1:10:54s\n",
      "epoch 22 | loss: 23.79992| val_0_rmse: 4.68762 |  1:14:08s\n",
      "epoch 23 | loss: 23.74104| val_0_rmse: 5.03422 |  1:17:21s\n",
      "epoch 24 | loss: 23.60246| val_0_rmse: 4.83619 |  1:20:37s\n",
      "epoch 25 | loss: 23.50838| val_0_rmse: 4.70245 |  1:23:50s\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 20 and best_val_0_rmse = 4.61763\n",
      "[CV] END gamma=1.8, lambda_sparse=0.001, n_a=8, n_d=8, n_steps=4; total time=84.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 170.08176| val_0_rmse: 5.87679 |  0:03:13s\n",
      "epoch 1  | loss: 34.95658| val_0_rmse: 5.50333 |  0:06:26s\n",
      "epoch 2  | loss: 31.56354| val_0_rmse: 5.12102 |  0:09:38s\n",
      "epoch 3  | loss: 29.68325| val_0_rmse: 5.05456 |  0:12:51s\n",
      "epoch 4  | loss: 28.71626| val_0_rmse: 4.9785  |  0:16:04s\n",
      "epoch 5  | loss: 27.89781| val_0_rmse: 4.99712 |  0:19:18s\n",
      "epoch 6  | loss: 27.33984| val_0_rmse: 4.89244 |  0:22:34s\n",
      "epoch 7  | loss: 27.23834| val_0_rmse: 4.90843 |  0:25:48s\n",
      "epoch 8  | loss: 26.64229| val_0_rmse: 4.79239 |  0:29:05s\n",
      "epoch 9  | loss: 26.24368| val_0_rmse: 5.20057 |  0:32:19s\n",
      "epoch 10 | loss: 25.95345| val_0_rmse: 4.73752 |  0:35:33s\n",
      "epoch 11 | loss: 25.74519| val_0_rmse: 5.20648 |  0:38:47s\n",
      "epoch 12 | loss: 25.61863| val_0_rmse: 5.80089 |  0:42:01s\n",
      "epoch 13 | loss: 25.60446| val_0_rmse: 4.66851 |  0:45:15s\n",
      "epoch 14 | loss: 25.34043| val_0_rmse: 5.11816 |  0:48:29s\n",
      "epoch 15 | loss: 25.22958| val_0_rmse: 5.30434 |  0:51:42s\n",
      "epoch 16 | loss: 24.98236| val_0_rmse: 4.79592 |  0:54:58s\n",
      "epoch 17 | loss: 24.91755| val_0_rmse: 4.74179 |  0:58:11s\n",
      "epoch 18 | loss: 24.89732| val_0_rmse: 5.1579  |  1:01:24s\n",
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 13 and best_val_0_rmse = 4.66851\n",
      "[CV] END gamma=1.8, lambda_sparse=0.001, n_a=8, n_d=8, n_steps=4; total time=61.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 173.35832| val_0_rmse: 6.00569 |  0:03:13s\n",
      "epoch 1  | loss: 37.90009| val_0_rmse: 5.99259 |  0:06:27s\n",
      "epoch 2  | loss: 33.42831| val_0_rmse: 5.42925 |  0:09:41s\n",
      "epoch 3  | loss: 32.27217| val_0_rmse: 5.13414 |  0:12:56s\n",
      "epoch 4  | loss: 30.753  | val_0_rmse: 5.47307 |  0:16:10s\n",
      "epoch 5  | loss: 30.60588| val_0_rmse: 5.10349 |  0:19:24s\n",
      "epoch 6  | loss: 29.68492| val_0_rmse: 5.25938 |  0:22:38s\n",
      "epoch 7  | loss: 29.21127| val_0_rmse: 4.98041 |  0:25:52s\n",
      "epoch 8  | loss: 29.5737 | val_0_rmse: 4.92386 |  0:29:07s\n",
      "epoch 9  | loss: 28.58455| val_0_rmse: 5.10433 |  0:32:21s\n",
      "epoch 10 | loss: 27.89667| val_0_rmse: 5.65346 |  0:35:36s\n",
      "epoch 11 | loss: 27.82982| val_0_rmse: 5.6822  |  0:38:50s\n",
      "epoch 12 | loss: 27.79338| val_0_rmse: 5.24362 |  0:42:04s\n",
      "epoch 13 | loss: 27.58649| val_0_rmse: 4.80894 |  0:45:18s\n",
      "epoch 14 | loss: 27.27019| val_0_rmse: 5.0109  |  0:48:32s\n",
      "epoch 15 | loss: 26.81836| val_0_rmse: 4.95715 |  0:51:47s\n",
      "epoch 16 | loss: 27.01607| val_0_rmse: 4.95223 |  0:55:01s\n",
      "epoch 17 | loss: 26.59679| val_0_rmse: 4.82938 |  0:58:16s\n",
      "epoch 18 | loss: 26.33388| val_0_rmse: 4.92313 |  1:01:30s\n",
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 13 and best_val_0_rmse = 4.80894\n",
      "[CV] END gamma=2.0, lambda_sparse=0.0001, n_a=8, n_d=8, n_steps=4; total time=62.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 184.52376| val_0_rmse: 5.65431 |  0:03:14s\n",
      "epoch 1  | loss: 34.99884| val_0_rmse: 5.47675 |  0:06:28s\n",
      "epoch 2  | loss: 32.22398| val_0_rmse: 5.19164 |  0:09:43s\n",
      "epoch 3  | loss: 30.60436| val_0_rmse: 5.12247 |  0:12:57s\n",
      "epoch 4  | loss: 29.33378| val_0_rmse: 5.14475 |  0:16:12s\n",
      "epoch 5  | loss: 30.59069| val_0_rmse: 5.06578 |  0:19:28s\n",
      "epoch 6  | loss: 29.72388| val_0_rmse: 10.09958|  0:22:43s\n",
      "epoch 7  | loss: 29.52606| val_0_rmse: 5.11197 |  0:25:58s\n",
      "epoch 8  | loss: 28.87589| val_0_rmse: 4.9201  |  0:29:13s\n",
      "epoch 9  | loss: 27.65593| val_0_rmse: 4.92922 |  0:32:27s\n",
      "epoch 10 | loss: 26.77429| val_0_rmse: 4.8635  |  0:35:42s\n",
      "epoch 11 | loss: 26.43027| val_0_rmse: 4.9394  |  0:38:55s\n",
      "epoch 12 | loss: 27.03408| val_0_rmse: 4.8024  |  0:42:10s\n",
      "epoch 13 | loss: 27.15572| val_0_rmse: 5.07668 |  0:45:24s\n",
      "epoch 14 | loss: 26.60598| val_0_rmse: 5.00291 |  0:48:38s\n",
      "epoch 15 | loss: 26.16802| val_0_rmse: 4.79481 |  0:51:53s\n",
      "epoch 16 | loss: 25.7276 | val_0_rmse: 4.86686 |  0:55:07s\n",
      "epoch 17 | loss: 25.58714| val_0_rmse: 4.80224 |  0:58:22s\n",
      "epoch 18 | loss: 25.53363| val_0_rmse: 4.89134 |  1:01:37s\n",
      "epoch 19 | loss: 26.38486| val_0_rmse: 4.86343 |  1:04:52s\n",
      "epoch 20 | loss: 25.70194| val_0_rmse: 4.81499 |  1:08:07s\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 15 and best_val_0_rmse = 4.79481\n",
      "[CV] END gamma=2.0, lambda_sparse=0.0001, n_a=8, n_d=8, n_steps=4; total time=68.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 176.48232| val_0_rmse: 5.81923 |  0:03:14s\n",
      "epoch 1  | loss: 36.75649| val_0_rmse: 5.30334 |  0:06:29s\n",
      "epoch 2  | loss: 32.47313| val_0_rmse: 5.14554 |  0:09:44s\n",
      "epoch 3  | loss: 30.32817| val_0_rmse: 5.42769 |  0:12:58s\n",
      "epoch 4  | loss: 29.27796| val_0_rmse: 5.06991 |  0:16:13s\n",
      "epoch 5  | loss: 28.48669| val_0_rmse: 5.0925  |  0:19:27s\n",
      "epoch 6  | loss: 27.97495| val_0_rmse: 4.83621 |  0:22:41s\n",
      "epoch 7  | loss: 27.4486 | val_0_rmse: 5.037   |  0:25:55s\n",
      "epoch 8  | loss: 26.95224| val_0_rmse: 4.88382 |  0:29:08s\n",
      "epoch 9  | loss: 26.75659| val_0_rmse: 4.85651 |  0:32:22s\n",
      "epoch 10 | loss: 26.51973| val_0_rmse: 5.00924 |  0:35:36s\n",
      "epoch 11 | loss: 26.18286| val_0_rmse: 4.85744 |  0:38:50s\n",
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 6 and best_val_0_rmse = 4.83621\n",
      "[CV] END gamma=2.0, lambda_sparse=0.0001, n_a=8, n_d=8, n_steps=4; total time=39.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 174.79991| val_0_rmse: 5.96452 |  0:03:13s\n",
      "epoch 1  | loss: 36.47073| val_0_rmse: 5.5223  |  0:06:27s\n",
      "epoch 2  | loss: 32.812  | val_0_rmse: 5.68049 |  0:09:40s\n",
      "epoch 3  | loss: 30.60224| val_0_rmse: 5.41939 |  0:12:54s\n",
      "epoch 4  | loss: 29.05183| val_0_rmse: 5.15843 |  0:16:08s\n",
      "epoch 5  | loss: 28.35683| val_0_rmse: 4.91803 |  0:19:22s\n",
      "epoch 6  | loss: 27.60014| val_0_rmse: 6.5804  |  0:22:36s\n",
      "epoch 7  | loss: 27.1669 | val_0_rmse: 11.17288|  0:25:51s\n",
      "epoch 8  | loss: 26.74896| val_0_rmse: 5.25218 |  0:29:05s\n",
      "epoch 9  | loss: 26.33217| val_0_rmse: 5.19999 |  0:32:18s\n",
      "epoch 10 | loss: 26.08863| val_0_rmse: 5.11654 |  0:35:32s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 5 and best_val_0_rmse = 4.91803\n",
      "[CV] END gamma=2.0, lambda_sparse=0.001, n_a=8, n_d=8, n_steps=4; total time=36.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 159.60835| val_0_rmse: 5.55581 |  0:03:13s\n",
      "epoch 1  | loss: 33.55218| val_0_rmse: 5.88878 |  0:06:26s\n",
      "epoch 2  | loss: 30.5149 | val_0_rmse: 5.01947 |  0:09:41s\n",
      "epoch 3  | loss: 28.95689| val_0_rmse: 5.38615 |  0:12:57s\n",
      "epoch 4  | loss: 28.15463| val_0_rmse: 5.39253 |  0:16:10s\n",
      "epoch 5  | loss: 27.55531| val_0_rmse: 4.83583 |  0:19:24s\n",
      "epoch 6  | loss: 27.09008| val_0_rmse: 4.91575 |  0:22:39s\n",
      "epoch 7  | loss: 26.72773| val_0_rmse: 4.95246 |  0:25:54s\n",
      "epoch 8  | loss: 26.59884| val_0_rmse: 5.20878 |  0:29:08s\n",
      "epoch 9  | loss: 27.00454| val_0_rmse: 5.1478  |  0:32:21s\n",
      "epoch 10 | loss: 26.26479| val_0_rmse: 4.79957 |  0:35:35s\n",
      "epoch 11 | loss: 25.52383| val_0_rmse: 4.72539 |  0:38:49s\n",
      "epoch 12 | loss: 25.15853| val_0_rmse: 4.71981 |  0:42:04s\n",
      "epoch 13 | loss: 24.92474| val_0_rmse: 4.80055 |  0:45:16s\n",
      "epoch 14 | loss: 26.76759| val_0_rmse: 4.67992 |  0:48:30s\n",
      "epoch 15 | loss: 26.28889| val_0_rmse: 5.21331 |  0:51:44s\n",
      "epoch 16 | loss: 25.25662| val_0_rmse: 4.74106 |  0:54:59s\n",
      "epoch 17 | loss: 24.92317| val_0_rmse: 4.77367 |  0:58:12s\n",
      "epoch 18 | loss: 24.72651| val_0_rmse: 4.73248 |  1:01:25s\n",
      "epoch 19 | loss: 24.39483| val_0_rmse: 4.64893 |  1:04:39s\n",
      "epoch 20 | loss: 24.37552| val_0_rmse: 4.63506 |  1:07:52s\n",
      "epoch 21 | loss: 24.13435| val_0_rmse: 4.53066 |  1:11:06s\n",
      "epoch 22 | loss: 23.99843| val_0_rmse: 4.63682 |  1:14:20s\n",
      "epoch 23 | loss: 23.73073| val_0_rmse: 4.78706 |  1:17:33s\n",
      "epoch 24 | loss: 23.55129| val_0_rmse: 4.75534 |  1:20:46s\n",
      "epoch 25 | loss: 23.73783| val_0_rmse: 4.6783  |  1:23:59s\n",
      "epoch 26 | loss: 23.63739| val_0_rmse: 4.82068 |  1:27:13s\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 21 and best_val_0_rmse = 4.53066\n",
      "[CV] END gamma=2.0, lambda_sparse=0.001, n_a=8, n_d=8, n_steps=4; total time=87.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 166.00718| val_0_rmse: 5.66829 |  0:03:13s\n",
      "epoch 1  | loss: 35.01276| val_0_rmse: 5.55814 |  0:06:27s\n",
      "epoch 2  | loss: 31.24336| val_0_rmse: 5.26052 |  0:09:40s\n",
      "epoch 3  | loss: 29.43727| val_0_rmse: 5.20063 |  0:12:54s\n",
      "epoch 4  | loss: 28.30453| val_0_rmse: 5.1571  |  0:16:08s\n",
      "epoch 5  | loss: 27.751  | val_0_rmse: 4.97945 |  0:19:21s\n",
      "epoch 6  | loss: 27.15114| val_0_rmse: 4.96472 |  0:22:37s\n",
      "epoch 7  | loss: 26.64624| val_0_rmse: 6.07173 |  0:25:52s\n",
      "epoch 8  | loss: 26.36044| val_0_rmse: 5.32476 |  0:29:07s\n",
      "epoch 9  | loss: 26.03431| val_0_rmse: 7.34531 |  0:32:21s\n",
      "epoch 10 | loss: 25.80265| val_0_rmse: 5.29645 |  0:35:36s\n",
      "epoch 11 | loss: 25.50959| val_0_rmse: 7.89704 |  0:38:51s\n",
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 6 and best_val_0_rmse = 4.96472\n",
      "[CV] END gamma=2.0, lambda_sparse=0.001, n_a=8, n_d=8, n_steps=4; total time=39.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 12 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n12 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py\", line 278, in fit\n    self.feature_importances_ = self._compute_feature_importances(X_train)\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py\", line 759, in _compute_feature_importances\n    M_explain, _ = self.explain(X, normalize=False)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py\", line 353, in explain\n    for batch_nb, data in enumerate(dataloader):\n  File \"c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 631, in __next__\n    data = self._next_data()\n           ^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 675, in _next_data\n    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 277, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 121, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 181, in collate_numpy_array_fn\n    raise TypeError(default_collate_err_msg_format.format(elem.dtype))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 46\u001b[0m\n\u001b[0;32m     36\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     37\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mtabnet, \n\u001b[0;32m     38\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     43\u001b[0m )\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# 조기 중지 설정을 포함하여 모델 학습\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 최대 에포크 수를 줄임\u001b[39;49;00m\n\u001b[0;32m     48\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m                \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrmse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m                \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_np\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters found by Grid Search:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest cross-validation MSE by Grid Search:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m-\u001b[39mgrid_search\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:947\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    942\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    943\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    944\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    945\u001b[0m     )\n\u001b[1;32m--> 947\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:536\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    530\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    531\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    535\u001b[0m     )\n\u001b[1;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    539\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    546\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 12 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n12 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py\", line 278, in fit\n    self.feature_importances_ = self._compute_feature_importances(X_train)\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py\", line 759, in _compute_feature_importances\n    M_explain, _ = self.explain(X, normalize=False)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py\", line 353, in explain\n    for batch_nb, data in enumerate(dataloader):\n  File \"c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 631, in __next__\n    data = self._next_data()\n           ^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 675, in _next_data\n    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 277, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 121, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 181, in collate_numpy_array_fn\n    raise TypeError(default_collate_err_msg_format.format(elem.dtype))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 준비 (train 데이터프레임이 이미 정의되어 있어야 합니다)\n",
    "# 예시: train = pd.read_csv('train.csv')\n",
    "X = train.drop('전력기상지수', axis=1)\n",
    "y = train['전력기상지수']\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# numpy 배열로 변환\n",
    "y_train_np = y_train.values.reshape(-1, 1)\n",
    "y_val_np = y_val.values.reshape(-1, 1)\n",
    "X_train_np = X_train.values\n",
    "X_val_np = X_val.values\n",
    "\n",
    "# 그리드 서치 파라미터 설정 (범위를 좁혀서)\n",
    "param_grid = {\n",
    "    'n_d': [8],  # 범위 좁힘\n",
    "    'n_a': [8],  # 범위 좁힘\n",
    "    'n_steps': [4],  # 범위 좁힘\n",
    "    'gamma': [1.8, 2.0],  # 범위 좁힘\n",
    "    'lambda_sparse': [0.0001, 0.001]  # 범위 좁힘\n",
    "}\n",
    "\n",
    "# TabNet 모델 생성 (새로운 객체로)\n",
    "tabnet = TabNetRegressor()\n",
    "\n",
    "# GridSearchCV 설정\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=tabnet, \n",
    "    param_grid=param_grid, \n",
    "    cv=3, \n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=1,  # 가능한 모든 프로세서를 사용\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 조기 중지 설정을 포함하여 모델 학습\n",
    "grid_search.fit(X_train_np, y_train_np, \n",
    "                max_epochs=30,  # 최대 에포크 수를 줄임\n",
    "                patience=5, \n",
    "                eval_metric=['rmse'], \n",
    "                eval_set=[(X_val_np, y_val_np)])\n",
    "\n",
    "print(\"Best parameters found by Grid Search:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation MSE by Grid Search:\", -grid_search.best_score_)\n",
    "\n",
    "# 검증 데이터에 대한 예측\n",
    "y_pred_grid = grid_search.predict(X_val_np)\n",
    "\n",
    "# 평가 지표 계산\n",
    "mae = mean_absolute_error(y_val_np, y_pred_grid)\n",
    "mse = mean_squared_error(y_val_np, y_pred_grid)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val_np, y_pred_grid)\n",
    "\n",
    "print(\"Validation MAE by Grid Search:\", mae)\n",
    "print(\"Validation MSE by Grid Search:\", mse)\n",
    "print(\"Validation RMSE by Grid Search:\", rmse)\n",
    "print(\"Validation R² by Grid Search:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (6074544, 95)\n",
      "<class 'numpy.ndarray'> (6074544, 1)\n",
      "<class 'numpy.ndarray'> (1518637, 95)\n",
      "<class 'numpy.ndarray'> (1518637, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 127.36815| val_0_rmse: 5.78054 |  0:04:35s\n",
      "epoch 1  | loss: 34.25357| val_0_rmse: 5.8888  |  0:09:06s\n",
      "epoch 2  | loss: 30.92995| val_0_rmse: 5.10062 |  0:13:38s\n",
      "epoch 3  | loss: 29.65534| val_0_rmse: 5.21534 |  0:18:11s\n",
      "epoch 4  | loss: 28.84016| val_0_rmse: 5.03884 |  0:22:43s\n",
      "epoch 5  | loss: 28.03538| val_0_rmse: 4.74181 |  0:27:15s\n",
      "epoch 6  | loss: 27.43432| val_0_rmse: 4.92455 |  0:31:48s\n",
      "Stop training because you reached max_epochs = 7 with best_epoch = 5 and best_val_0_rmse = 4.74181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m model \u001b[38;5;241m=\u001b[39m TabNetRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_np\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 최대 에포크 수를 줄임\u001b[39;49;00m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrmse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_np\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:278\u001b[0m, in \u001b[0;36mTabModel.fit\u001b[1;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations, compute_importance)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_importance:\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;66;03m# compute feature importance once the best model is defined\u001b[39;00m\n\u001b[1;32m--> 278\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_importances_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_feature_importances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:759\u001b[0m, in \u001b[0;36mTabModel._compute_feature_importances\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_feature_importances\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    751\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute global feature importance.\u001b[39;00m\n\u001b[0;32m    752\u001b[0m \n\u001b[0;32m    753\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    757\u001b[0m \n\u001b[0;32m    758\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 759\u001b[0m     M_explain, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m     sum_explain \u001b[38;5;241m=\u001b[39m M_explain\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    761\u001b[0m     feature_importances_ \u001b[38;5;241m=\u001b[39m sum_explain \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(sum_explain)\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:369\u001b[0m, in \u001b[0;36mTabModel.explain\u001b[1;34m(self, X, normalize)\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m masks\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 369\u001b[0m             res_masks[key] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mres_masks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    371\u001b[0m res_explain \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(res_explain)\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n",
      "File \u001b[1;32mc:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\shape_base.py:289\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    288\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[1;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import joblib\n",
    "\n",
    "# 데이터 준비\n",
    "X = train.drop('전력기상지수', axis=1)\n",
    "y = train['전력기상지수']\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 목표 변수 numpy array로 변환 후 reshape\n",
    "y_train_np = y_train.values.reshape(-1, 1)\n",
    "y_val_np = y_val.values.reshape(-1, 1)\n",
    "\n",
    "# 데이터 numpy array로 변환\n",
    "X_train_np = X_train.values\n",
    "X_val_np = X_val.values\n",
    "\n",
    "# 데이터 타입과 모양 확인\n",
    "print(type(X_train_np), X_train_np.shape)\n",
    "print(type(y_train_np), y_train_np.shape)\n",
    "print(type(X_val_np), X_val_np.shape)\n",
    "print(type(y_val_np), y_val_np.shape)\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "params = {\n",
    "    'n_d': 8,\n",
    "    'n_a': 8,\n",
    "    'n_steps': 4,\n",
    "    'gamma': 2.0,\n",
    "    'lambda_sparse': 0.001\n",
    "}\n",
    "\n",
    "# TabNet Regressor 모델 정의 및 설정\n",
    "model = TabNetRegressor(**params)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(\n",
    "    X_train_np, y_train_np,\n",
    "    max_epochs=7,  # 최대 에포크 수를 줄임\n",
    "    patience=2, \n",
    "    eval_metric=['rmse'], \n",
    "    eval_set=[(X_val_np, y_val_np)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "# model.save_model('best_tabnet_model')\n",
    "\n",
    "# print(f\"Best model saved to 'best_tabnet_model.zip'\")\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "# 최적 모델 로드 및 검증 데이터로 예측 수행\n",
    "loaded_model = TabNetRegressor()\n",
    "loaded_model.load_model(r'C:/Users/DC/OneDrive - 계명대학교/DC/2024/2024_날씨빅콘/코드/best_tabnet_model.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object 타입의 열: Index(['계절'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "object_columns = test.select_dtypes(include=['object']).columns\n",
    "print(\"Object 타입의 열:\", object_columns)\n",
    "test = pd.get_dummies(test, columns=object_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boolean 값을 정수형으로 변환\n",
    "test = test.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_test_np = test.values\n",
    "\n",
    "# 최종 모델을 사용하여 test 데이터셋에 대한 예측 수행\n",
    "y_test_pred = loaded_model.predict(X_test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:/Users/DC/OneDrive - 계명대학교/DC/2024/2024_날씨빅콘/제출데셋/electric_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_nan(df, nan_value=-99):\n",
    "#     for column in df.columns:\n",
    "#         df = df[df[column] != nan_value]\n",
    "#     return df\n",
    "\n",
    "\n",
    "# df = remove_nan(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = len(df)\n",
    "n_pred = len(y_test_pred)\n",
    "\n",
    "if n_test != n_pred:\n",
    "    # 예측값 길이와 데이터프레임 길이 차이 계산\n",
    "    diff = n_test - n_pred\n",
    "    \n",
    "    # 앞뒤 평균으로 채울 값을 생성\n",
    "    y_test_pred_extended = list(y_test_pred)\n",
    "    \n",
    "    for i in range(diff):\n",
    "        # 앞뒤 평균으로 결측값을 채움\n",
    "        if i == 0:\n",
    "            # 처음에 추가할 경우\n",
    "            y_test_pred_extended.insert(0, (y_test_pred_extended[0] + y_test_pred_extended[1]) / 2)\n",
    "        else:\n",
    "            # 그 외의 경우\n",
    "            y_test_pred_extended.append((y_test_pred_extended[-1] + y_test_pred_extended[-2]) / 2)\n",
    "\n",
    "    y_test_pred = np.array(y_test_pred_extended)\n",
    "\n",
    "# 데이터프레임에 예측값 추가\n",
    "df['elect'] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUM</th>\n",
       "      <th>TM</th>\n",
       "      <th>HH24</th>\n",
       "      <th>STN</th>\n",
       "      <th>nph_ta</th>\n",
       "      <th>nph_hm</th>\n",
       "      <th>nph_ws_10m</th>\n",
       "      <th>nph_rn_60m</th>\n",
       "      <th>nph_ta_chi</th>\n",
       "      <th>weekday</th>\n",
       "      <th>week_name</th>\n",
       "      <th>elect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2385</td>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>303</td>\n",
       "      <td>7.8</td>\n",
       "      <td>61.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.594788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2385</td>\n",
       "      <td>2023-01-01 02:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>303</td>\n",
       "      <td>7.9</td>\n",
       "      <td>60.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.450401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2385</td>\n",
       "      <td>2023-01-01 03:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>303</td>\n",
       "      <td>8.2</td>\n",
       "      <td>61.9</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.739174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2385</td>\n",
       "      <td>2023-01-01 04:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>303</td>\n",
       "      <td>8.4</td>\n",
       "      <td>60.9</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.930763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2385</td>\n",
       "      <td>2023-01-01 05:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>303</td>\n",
       "      <td>8.5</td>\n",
       "      <td>60.9</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.406364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838234</th>\n",
       "      <td>12322</td>\n",
       "      <td>2023-12-31 19:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>901</td>\n",
       "      <td>5.7</td>\n",
       "      <td>72.3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.669601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838235</th>\n",
       "      <td>12322</td>\n",
       "      <td>2023-12-31 20:00:00</td>\n",
       "      <td>20</td>\n",
       "      <td>901</td>\n",
       "      <td>5.6</td>\n",
       "      <td>70.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.669601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838236</th>\n",
       "      <td>12322</td>\n",
       "      <td>2023-12-31 21:00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>901</td>\n",
       "      <td>5.3</td>\n",
       "      <td>69.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.669601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838237</th>\n",
       "      <td>12322</td>\n",
       "      <td>2023-12-31 22:00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>901</td>\n",
       "      <td>5.1</td>\n",
       "      <td>70.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.669601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838238</th>\n",
       "      <td>12322</td>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>901</td>\n",
       "      <td>5.2</td>\n",
       "      <td>69.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.669601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2838239 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           NUM                   TM  HH24  STN  nph_ta  nph_hm  nph_ws_10m  \\\n",
       "0         2385  2023-01-01 01:00:00     1  303     7.8    61.5         6.7   \n",
       "1         2385  2023-01-01 02:00:00     2  303     7.9    60.6         7.6   \n",
       "2         2385  2023-01-01 03:00:00     3  303     8.2    61.9         8.7   \n",
       "3         2385  2023-01-01 04:00:00     4  303     8.4    60.9         9.2   \n",
       "4         2385  2023-01-01 05:00:00     5  303     8.5    60.9         9.5   \n",
       "...        ...                  ...   ...  ...     ...     ...         ...   \n",
       "2838234  12322  2023-12-31 19:00:00    19  901     5.7    72.3         3.6   \n",
       "2838235  12322  2023-12-31 20:00:00    20  901     5.6    70.8         3.2   \n",
       "2838236  12322  2023-12-31 21:00:00    21  901     5.3    69.1         3.6   \n",
       "2838237  12322  2023-12-31 22:00:00    22  901     5.1    70.6         3.0   \n",
       "2838238  12322  2023-12-31 23:00:00    23  901     5.2    69.7         3.8   \n",
       "\n",
       "         nph_rn_60m  nph_ta_chi  weekday  week_name       elect  \n",
       "0               0.0         4.2        6        1.0   95.594788  \n",
       "1               0.0         4.0        6        1.0   95.450401  \n",
       "2               0.0         4.1        6        1.0   95.739174  \n",
       "3               0.0         4.3        6        1.0   99.930763  \n",
       "4               0.0         4.3        6        1.0   98.406364  \n",
       "...             ...         ...      ...        ...         ...  \n",
       "2838234         0.0         5.7        6        1.0  101.669601  \n",
       "2838235         0.0         5.8        6        1.0  101.669601  \n",
       "2838236         0.0         4.5        6        1.0  101.669601  \n",
       "2838237         0.0         5.1        6        1.0  101.669601  \n",
       "2838238         0.0         5.1        6        1.0  101.669601  \n",
       "\n",
       "[2838239 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:/Users/DC/OneDrive - 계명대학교/DC/2024/2024_날씨빅콘/제출데셋/240223.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
